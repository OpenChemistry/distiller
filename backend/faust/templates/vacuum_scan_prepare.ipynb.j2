{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare a vacuum scan for subtraction from other scans\n",
    " - Once completed, use vacuum_scan_subtract.ipynb to apply the vacuum scan subtraction to other scans\n",
    " - Each scan must have the same STEM magnification and camera length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm,PowerNorm\n",
    "from matplotlib.patches import Circle\n",
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "import imageio\n",
    "from scipy import ndimage\n",
    "\n",
    "import stempy.io as stio\n",
    "import stempy.image as stim\n",
    "from stempy.contrib import get_scan_path\n",
    "\n",
    "import ncempy\n",
    "\n",
    "def planeFit(points):\n",
    "    \"\"\"\n",
    "    p, n = planeFit(points)\n",
    "\n",
    "    Given an array, points, of shape (d,...)\n",
    "    representing points in d-dimensional space,\n",
    "    fit an d-dimensional plane to the points.\n",
    "    Return a point, p, on the plane (the point-cloud centroid),\n",
    "    and the normal, n.\n",
    "    \"\"\"\n",
    "    points = np.reshape(points, (np.shape(points)[0], -1)) # Collapse trialing dimensions\n",
    "    assert points.shape[0] <= points.shape[1], \"There are only {} points in {} dimensions.\".format(points.shape[1], points.shape[0])\n",
    "    ctr = points.mean(axis=1)\n",
    "    x = points - ctr[:,np.newaxis]\n",
    "    M = np.dot(x, x.T) # Could also use np.cov(x) here.\n",
    "    return ctr, svd(M)[0][:,-1]\n",
    "\n",
    "distiller_path = Path('{{ settings.NCEMHUB_PATH }}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the vacuum scan data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close all previous windows to avoid too many windows\n",
    "plt.close('all')\n",
    "\n",
    "date = Path('{{scan_created_date}}')\n",
    "scan_id = {{ scan.id }}\n",
    "scan_num = {{ scan.scan_id }}\n",
    "th = None # optional; use None or integer\n",
    "\n",
    "fname, scan_num, scan_id = get_scan_path(distiller_path / Path('counted') / Path(date), scan_num, scan_id=scan_id, version=1)\n",
    "\n",
    "# Load the sparse data\n",
    "vacuum_scan = stio.load_electron_counts(fname, keep_flyback=False) # remove flyback\n",
    "\n",
    "print('File: {}'.format(fname))\n",
    "print('Scan dimensions = {}'.format(vacuum_scan.scan_shape))\n",
    "\n",
    "# Load the HAADF (if available)\n",
    "haadf_path = distiller_path / Path('dm4') / Path(date) / Path(f'scan{scan_num}.dm4')\n",
    "\n",
    "if haadf_path.exists():\n",
    "    with ncempy.io.dm.fileDM(haadf_path) as f0:\n",
    "        md = f0.getMetadata(0)\n",
    "        camera_length = md['Microscope Info STEM Camera Length']\n",
    "        stem_magnification = md['Microscope Info Indicated Magnification']\n",
    "        print(f'Camera length = {camera_length} mm')\n",
    "        print(f'STEM magnification = {stem_magnification} kx')\n",
    "else:\n",
    "    print('No HAADF available')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the center of the center beam at each scan position\n",
    " - $center$ variable should be the average x and y position of the beam\n",
    " - $radius$ variable should contain all possible positions of the beam. All electrons outside this radius will be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the summed diffraction pattern to set hyperparameters\n",
    "dp = vacuum_scan.sum(axis=(0, 1))\n",
    "\n",
    "# Get a single dense diffraction pattern from the center\n",
    "dp0 = vacuum_scan[vacuum_scan.scan_shape[0]//2, vacuum_scan.scan_shape[1]//2, :, :]\n",
    "\n",
    "# Set the center of the pattern (use figure below for manual)\n",
    "center = stim.com_dense(dp) # use the center of mass of the summed pattern\n",
    "#center = (287, 287) # manually define as column, row from plot (if automated technique fails)\n",
    "print(f'Average center of beam = {center}')\n",
    "\n",
    "# Define the radius for iterative processing\n",
    "radius = 30 # pixels\n",
    "\n",
    "fg,ax = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "ax[1].imshow(dp, norm=PowerNorm(0.75))\n",
    "ax[1].scatter(center[0], center[1], c='r')\n",
    "ax[1].add_patch(Circle(center, radius=radius, fc=None, fill=None, ec='r'))\n",
    "ax[0].imshow(dp0, norm=PowerNorm(0.75))\n",
    "ax[0].set(title='single pattern')\n",
    "ax[1].set(title='summed pattern')\n",
    "ax[1].legend(['center of pattern', 'crop_to radius']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the center of mass (COM) iteratively for each scan position\n",
    "com2 = stim.com_sparse(vacuum_scan, crop_to=(radius, radius), init_center=center[::-1])\n",
    "\n",
    "com2_median = np.median(com2, axis=(1,2))\n",
    "com2_std = np.std(com2, axis=(1,2))\n",
    "\n",
    "fg,ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(com2[0,]-com2_median[0], vmin=-com2_std[0]*3, vmax=com2_std[0]*3, cmap='bwr')\n",
    "ax[0].set(title='COM: axis 0')\n",
    "ax[1].imshow(com2[1,]-com2_median[1], vmin=-com2_std[1]*3, vmax=com2_std[1]*3, cmap='bwr')\n",
    "ax[1].set(title='COM: axis 1')\n",
    "\n",
    "fg,ax = plt.subplots(1, 2)\n",
    "ax[0].hist(com2[0,].ravel() - com2_median[0])\n",
    "ax[0].set(title='COM: axis 0')\n",
    "ax[1].hist(com2[1,].ravel()-com2_median[1])\n",
    "ax[1].set(title='COM: axis 1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the outliers by median filtering\n",
    "com2_filt = np.zeros_like(com2)\n",
    "com2_filt[0,] = ndimage.median_filter(com2[0,], size=(5, 5))\n",
    "com2_filt[1,] = ndimage.median_filter(com2[1,], size=(5, 5))\n",
    "\n",
    "com2_median = np.median(com2_filt, axis=(1, 2))\n",
    "\n",
    "fg,ax = plt.subplots(1, 2,sharex=True,sharey=True)\n",
    "ax[0].imshow(com2_filt[0,]-com2_median[0],cmap='bwr',vmin=-3,vmax=3)\n",
    "ax[0].set(title='COM: axis 0')\n",
    "ax[1].imshow(com2_filt[1,]-com2_median[1],cmap='bwr',vmin=-3,vmax=3);\n",
    "ax[1].set(title='COM: axis 1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the beam motion to reduce noise\n",
    " - If the motion is linear then a plane is sufficient\n",
    " - If the motion is non-linear then use interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate to fit the vacuum scan_shape\n",
    "\n",
    "YY, XX = np.mgrid[0:com2.shape[1], 0:com2.shape[2]]\n",
    "\n",
    "# Interpolation\n",
    "com2_fit = np.zeros((2, *XX.shape))\n",
    "com2_fit[0,:,:] = ndimage.map_coordinates(com2_filt[0,:,:], (YY.ravel(), XX.ravel()),mode='nearest').reshape(XX.shape)\n",
    "com2_fit[1,:,:] = ndimage.map_coordinates(com2_filt[1,:,:], (YY.ravel(), XX.ravel()),mode='nearest').reshape(XX.shape)\n",
    "\n",
    "com2_fit_median = np.median(com2_fit,axis=(1,2))\n",
    "\n",
    "# Fit to a plane\n",
    "planeCOM0 = planeFit(np.stack((YY, XX, com2_filt[0,]-com2_median[0])))\n",
    "planeCOM1 = planeFit(np.stack((YY, XX, com2_filt[1,]-com2_median[1])))\n",
    "\n",
    "print(f'plane fit to COM0: {planeCOM0}')\n",
    "print(f'plane fit to COM1: {planeCOM1}')\n",
    "\n",
    "normal = planeCOM0[1]\n",
    "d = np.dot(-planeCOM0[0], normal)\n",
    "# calculate corresponding z\n",
    "z0 = (-normal[0]*YY - normal[1]*XX - d)/normal[2]\n",
    "\n",
    "normal = planeCOM1[1]\n",
    "d = np.dot(-planeCOM1[0], normal)\n",
    "# calculate corresponding z\n",
    "z1 = (-normal[0]*YY - normal[1]*XX - d)/normal[2]\n",
    "\n",
    "# Plot everything together\n",
    "fg,ax = plt.subplots(2, 3)\n",
    "ax[0, 0].imshow(com2_filt[0,],cmap='bwr')\n",
    "ax[0, 0].set(title='Experimental')\n",
    "ax[0, 1].imshow(z0, cmap='bwr')\n",
    "ax[0, 1].set(title='Linear plane fit')\n",
    "ax[1, 0].imshow(com2_filt[1,],cmap='bwr')\n",
    "ax[1, 1].imshow(z1, cmap='bwr')\n",
    "ax[0, 2].imshow(com2_fit[0,]-com2_fit_median[0], cmap='bwr')\n",
    "ax[1, 2].imshow(com2_fit[1,]-com2_fit_median[1], cmap='bwr')\n",
    "ax[0, 2].set(title='Interpolation')\n",
    "fg.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove shifts from the vacuum scan to test the fit\n",
    " - Set the $method$ variable according to the type of shift you want to use in the correction (usually interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test centering on the vacuum scan itself\n",
    "method = 'interp' # choose plane or interp\n",
    "\n",
    "if method == 'interp':\n",
    "    scan_origin0 = com2_fit[0,]\n",
    "    scan_origin1 = com2_fit[1,]\n",
    "elif method == 'plane':\n",
    "    scan_origin0 = z0\n",
    "    scan_origin1 = z1\n",
    "else:\n",
    "    raise ValueError(f\"Incorrrect method: {method}\")\n",
    "scan_origin0_round = np.round(scan_origin0).astype(np.int32) - int(scan_origin0.mean())\n",
    "scan_origin1_round = np.round(scan_origin1).astype(np.int32) - int(scan_origin1.mean())\n",
    "\n",
    "# Ensure the data sets are the same size\n",
    "assert vacuum_scan.data.shape[0] == scan_origin0_round.ravel().shape[0]\n",
    "\n",
    "centered = np.empty_like(vacuum_scan.data)\n",
    "for ii, (eev, x, y) in enumerate(zip(vacuum_scan.data, scan_origin0_round.ravel(), scan_origin1_round.ravel())):\n",
    "    for jj, ev in enumerate(eev):\n",
    "        evx, evy = np.unravel_index(ev, vacuum_scan.frame_shape)\n",
    "        evx_centered = evx - y # need to flip x and y\n",
    "        evy_centered = evy - x\n",
    "\n",
    "        # Some events will get pushed off the detector by the shift. Remove them\n",
    "        keep = (evx_centered < vacuum_scan.frame_shape[0]) & (evx_centered >= 0) & (evy_centered < vacuum_scan.frame_shape[1]) & (evy_centered >= 0)\n",
    "        evx_centered = evx_centered[keep]\n",
    "        evy_centered = evy_centered[keep]\n",
    "\n",
    "        centered[ii, jj] = np.ravel_multi_index((evx_centered,evy_centered), vacuum_scan.frame_shape)\n",
    "\n",
    "vacuum_scan_centered = stio.SparseArray(centered, vacuum_scan.scan_shape, vacuum_scan.frame_shape)\n",
    "\n",
    "dp = vacuum_scan.sum(axis=(0,1))\n",
    "dp2 = vacuum_scan_centered.sum(axis=(0,1))\n",
    "\n",
    "fg,ax = plt.subplots(1,2,sharex=True,sharey=True)\n",
    "ax[0].imshow(dp)\n",
    "ax[0].set(title='Summed raw data')\n",
    "ax[1].imshow(dp2)\n",
    "ax[1].set(title='Summed centered data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data for use on other datasets\n",
    "\n",
    "# Save the centered vacuum scan to a stempy dataset\n",
    "scan_out_path = fname.with_name(fname.stem + '_centered.h5')\n",
    "vacuum_scan_centered.write_to_hdf5(scan_out_path)\n",
    "print(f'Centered scan saved to: {scan_out_path}')\n",
    "\n",
    "# Save the scan shift data as an EMD file\n",
    "offsets_out_path = fname.with_name(fname.stem + '_offsets.emd')\n",
    "\n",
    "if offsets_out_path.exists():\n",
    "    raise FileExistsError(f'Offsets file {offsets_out_path} already exists.\\nDelete and resave to update the file')\n",
    "else:\n",
    "    with ncempy.io.emd.fileEMD(offsets_out_path, readonly=False) as f0:\n",
    "        dims0 = ncempy.io.emd.defaultDims(com2_filt)\n",
    "        f0.put_emdgroup('vacuum_COM', com2_filt, dims0)\n",
    "    print(f'Offsets saved to: {offsets_out_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stempy-jupyterlab",
   "language": "python",
   "name": "stempy-jupyterlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
